{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+CLFPJ/ZKcmmQjbQWdiAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdiVM/Neuro240/blob/main/Neuro240FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_PdcJlQyDlD",
        "outputId": "cb0db024-dcf5-4884-8f5b-92092c7786f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# All future runs can start here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_path = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/Data_Entry_2017_v2020.csv\"\n",
        "image_folder = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/images\"\n",
        "\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(\"Metdata loaded\")\n",
        "\n",
        "# Filtering the metadata to find images labeled either no finding or those containing the word mass\n",
        "filtered_metadata = metadata[\n",
        "    (metadata[\"Finding Labels\"] == \"No Finding\") |\n",
        "    (metadata[\"Finding Labels\"].str.contains(\"Mass\", na=False))\n",
        "]\n",
        "\n",
        "filtered_image_indexes = set(filtered_metadata[\"Image Index\"])\n",
        "filtered_metadata = filtered_metadata.head(50000)\n",
        "\n",
        "matching_images = sorted(list(filtered_metadata[\"Image Index\"]))\n",
        "\n",
        "# Convert to stored list\n",
        "matching_images = sorted(list(matching_images))\n",
        "\n",
        "print(f\"Total matching images found: {len(matching_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8-T_YFvyEpR",
        "outputId": "b5325c7a-0361-40ed-dd27-cd202300a359"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metdata loaded\n",
            "Total matching images found: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now to perform stratified shuffle split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        " # Check class distribution before splitting\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n",
        "\n",
        "# There are many small classes of mass, so need to group them all together before splitting\n",
        "# Standardize labels: Convert anything containing \"Mass\" to just \"Mass\"\n",
        "filtered_metadata[\"Finding Labels\"] = filtered_metadata[\"Finding Labels\"].apply(\n",
        "    lambda x: \"Mass\" if \"Mass\" in x else x\n",
        ")\n",
        "\n",
        "# Verify new label counts\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xKqoPmUyLE-",
        "outputId": "eb333421-e6f5-4497-b6be-1a0cfcc8a99f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding Labels\n",
            "No Finding                                                                          45542\n",
            "Mass                                                                                 1708\n",
            "Infiltration|Mass                                                                     329\n",
            "Mass|Nodule                                                                           293\n",
            "Effusion|Mass                                                                         285\n",
            "                                                                                    ...  \n",
            "Effusion|Emphysema|Mass|Nodule                                                          1\n",
            "Atelectasis|Consolidation|Effusion|Fibrosis|Infiltration|Mass|Pleural_Thickening        1\n",
            "Atelectasis|Consolidation|Effusion|Fibrosis|Infiltration|Mass                           1\n",
            "Cardiomegaly|Consolidation|Effusion|Infiltration|Mass|Nodule                            1\n",
            "Edema|Fibrosis|Infiltration|Mass                                                        1\n",
            "Name: count, Length: 258, dtype: int64\n",
            "Finding Labels\n",
            "No Finding    45542\n",
            "Mass           4458\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\"No Finding\": 0, \"Mass\": 1}\n",
        "filtered_metadata[\"Label\"] = filtered_metadata[\"Finding Labels\"].map(label_map)"
      ],
      "metadata": {
        "id": "zxHdem9r6Ewk"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_metadata[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34yrTBQ83aFV",
        "outputId": "3304ed57-d48a-4076-e423-960d1b373c52"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "0    45542\n",
            "1     4458\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data while ensuring proportional distribution of classes\n",
        "train_metadata, test_metadata = train_test_split(\n",
        "    filtered_metadata,\n",
        "    test_size=0.2,\n",
        "    stratify=filtered_metadata[\"Label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Class distribution in train and test sets\n",
        "print(\"Training set:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"Testing Set:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xripsguQyPqP",
        "outputId": "5ca1ee51-9e81-47b6-cff4-ce60e5454411"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Label\n",
            "0    36434\n",
            "1     3566\n",
            "Name: count, dtype: int64\n",
            "Testing Set:\n",
            "Label\n",
            "0    9108\n",
            "1     892\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train metadata entries: {len(train_metadata)}\")\n",
        "print(f\"Test metadata entries: {len(test_metadata)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6h6-YhWySET",
        "outputId": "5b5ac2be-e2c7-4c4b-f5e7-b99e9835b953"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train metadata entries: 40000\n",
            "Test metadata entries: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering metdata\n",
        "train_image_files = set(train_metadata[\"Image Index\"])\n",
        "test_image_files = set(test_metadata[\"Image Index\"])\n",
        "\n",
        "train_images = sorted(list(train_image_files))\n",
        "test_images = sorted(list(test_image_files))\n",
        "\n",
        "# Convert to sorted lists for consistency\n",
        "train_images = sorted(list(train_images))\n",
        "test_images = sorted(list(test_images))\n",
        "\n",
        "\n",
        "print(f\"Total train images found: {len(train_images)}\")\n",
        "print(f\"Total test images found: {len(test_images)}\")\n",
        "\n",
        "# Print a few samples\n",
        "print(\"Sample train images:\", train_images[:10])\n",
        "print(\"Sample test images:\", test_images[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-cLJqxySmw",
        "outputId": "75ea1c40-7966-4bd1-9ac5-77c4f4bd2371"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images found: 40000\n",
            "Total test images found: 10000\n",
            "Sample train images: ['00000002_000.png', '00000004_000.png', '00000005_000.png', '00000005_002.png', '00000005_003.png', '00000005_004.png', '00000005_005.png', '00000006_000.png', '00000007_000.png', '00000011_002.png']\n",
            "Sample test images: ['00000005_001.png', '00000008_001.png', '00000011_001.png', '00000011_003.png', '00000013_000.png', '00000013_017.png', '00000013_029.png', '00000013_030.png', '00000018_000.png', '00000032_049.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Will use TensorFlow for model training\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JSullbIDyWwk"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing parameters\n",
        "image_size = (224, 224)  # Resize images\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Normalize pixel values\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Only rescale for testing\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load train images from directory\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")\n",
        "\n",
        "# Load test images\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaTNWs9lyY6O",
        "outputId": "b3b56900-fb10-4bf2-9028-92f297be5fbf"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40000 validated image filenames.\n",
            "Found 10000 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train distribution:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"\\nTest distribution:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lApFIyKt6dYr",
        "outputId": "ceda4766-47d9-4642-c4c7-4b32c81b16b9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train distribution:\n",
            "Label\n",
            "0    36434\n",
            "1     3566\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test distribution:\n",
            "Label\n",
            "0    9108\n",
            "1     892\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_subset(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=5,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/results\"):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    # Sample training and test subsets\n",
        "    train_metadata_subset = train_metadata.sample(train_size, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Save class distributions\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    train_dist = save_distribution(train_metadata_subset, \"train\")\n",
        "    test_dist = save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Combined barplot\n",
        "    combined_df = pd.concat([\n",
        "        train_dist[\"Percent\"].rename(\"Train\"),\n",
        "        test_dist[\"Percent\"].rename(\"Test\")\n",
        "    ], axis=1).fillna(0).reset_index()\n",
        "\n",
        "    # Rename the column to 'Label'\n",
        "    combined_df.columns.values[0] = \"Label\"\n",
        "\n",
        "    combined_df = pd.melt(combined_df, id_vars=\"Label\", var_name=\"Set\", value_name=\"Percent\")\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(data=combined_df, x=\"Label\", y=\"Percent\", hue=\"Set\")\n",
        "    plt.title(\"Class Distribution: Train vs Test\")\n",
        "    plt.ylabel(\"Percentage\")\n",
        "    plt.xlabel(\"Class Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{result_prefix}_class_distribution_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Image data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # CNN model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    y_true = test_generator.classes\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Save confusion matrix\n",
        "    confusion_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[\"Mass\", \"No Finding\"],\n",
        "    columns=[\"Predicted Mass\", \"Predicted No Finding\"])\n",
        "\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    # Save predictions\n",
        "    filenames = test_generator.filenames\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": y_pred,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    # Save ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc"
      ],
      "metadata": {
        "id": "_F0GVzmCyda9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, history, acc, auc = train_model_with_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=500\n",
        ")"
      ],
      "metadata": {
        "id": "GCDAtHGyyeAa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_250, history_250, acc_250, auc_250 = train_model_with_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=250\n",
        ")"
      ],
      "metadata": {
        "id": "Dt27vdnmyzGh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000, history_1000, acc_1000, auc_1000 = train_model_with_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")"
      ],
      "metadata": {
        "id": "9XlYdBJFyzj6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_250, history_250, acc_250, auc_250 = train_model_with_noise(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=500\n",
        ")"
      ],
      "metadata": {
        "id": "V7f0cO8Sy4A_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_class_weighting(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=5,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/results_class_weight\"):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    # Sample training and test subsets\n",
        "    half_size = train_size // 2\n",
        "    mass_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"Mass\"].sample(half_size, random_state=42)\n",
        "    no_finding_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"No Finding\"].sample(half_size, random_state=42)\n",
        "    train_metadata_subset = pd.concat([mass_subset, no_finding_subset]).sample(frac=1, random_state=42)  # Shuffle\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Save class distributions\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    train_dist = save_distribution(train_metadata_subset, \"train\")\n",
        "    test_dist = save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Combined barplot\n",
        "    combined_df = pd.concat([\n",
        "        train_dist[\"Percent\"].rename(\"Train\"),\n",
        "        test_dist[\"Percent\"].rename(\"Test\")\n",
        "    ], axis=1).fillna(0).reset_index()\n",
        "\n",
        "    # Rename the correct column to 'Label'\n",
        "    combined_df.columns.values[0] = \"Label\"\n",
        "\n",
        "    combined_df = pd.melt(combined_df, id_vars=\"Label\", var_name=\"Set\", value_name=\"Percent\")\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(data=combined_df, x=\"Label\", y=\"Percent\", hue=\"Set\")\n",
        "    plt.title(\"Class Distribution: Train vs Test\")\n",
        "    plt.ylabel(\"Percentage\")\n",
        "    plt.xlabel(\"Class Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{result_prefix}_class_distribution_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Image data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # CNN model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    import numpy as np\n",
        "\n",
        "    # Map labels to integers using the generator's class indices\n",
        "    label_map = train_generator.class_indices\n",
        "\n",
        "    # Convert y labels to 0/1\n",
        "    label_map = {\"No Finding\": 0, \"Mass\": 1}\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"].map(label_map)\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=np.array([0, 1]),\n",
        "        y=y_train_labels\n",
        "    )\n",
        "    class_weight_dict = dict(zip([0, 1], class_weights))\n",
        "\n",
        "    print(\"Class weights:\", class_weight_dict)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "    # Trying multiple thresholds to find the optimal one\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    thresholds = np.linspace(0.1, 0.9, 9)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5  # Baseline\n",
        "    best_preds = None\n",
        "\n",
        "    for t in thresholds:\n",
        "      preds = (y_pred_proba > t).astype(int)\n",
        "      f1 = f1_score(y_true, preds)\n",
        "      print(f\"Threshold {t:.2f} → F1 Score: {f1:.4f}\")\n",
        "      if f1 > best_f1:\n",
        "          best_f1 = f1\n",
        "          best_threshold = t\n",
        "          best_preds = preds\n",
        "\n",
        "    print(f\"\\nBest Threshold: {best_threshold:.2f} → F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, best_preds)\n",
        "\n",
        "    # Saving confusion matrix\n",
        "    confusion_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[\"Mass\", \"No Finding\"],\n",
        "    columns=[\"Predicted Mass\", \"Predicted No Finding\"])\n",
        "\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    # Save predictions\n",
        "    filenames = test_generator.filenames\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": best_preds,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    # Save ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "\n",
        "    with open(f\"{result_prefix}_best_threshold.txt\", \"w\") as f:\n",
        "      f.write(f\"Best threshold: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc"
      ],
      "metadata": {
        "id": "We89N-5FJo92"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_250_class, history_250_class, acc_250_class, auc_250_class = train_model_with_class_weighting(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=250\n",
        ")"
      ],
      "metadata": {
        "id": "c9HfxrncMS0W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_500_class, history_500_class, acc_500_class, auc_500_class = train_model_with_class_weighting(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=500\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh4T3ro8ZJWf",
        "outputId": "be99c89f-c3c0-4b0e-eda0-5ee5f3ab1896"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 500 validated image filenames belonging to 2 classes.\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Class weights:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " {0: np.float64(1.0), 1: np.float64(1.0)}\n",
            "Epoch 1/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 11s/step - accuracy: 0.4848 - loss: 1.4409 - val_accuracy: 0.8160 - val_loss: 0.6913\n",
            "Epoch 2/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 5s/step - accuracy: 0.4435 - loss: 0.6941 - val_accuracy: 0.1120 - val_loss: 0.6998\n",
            "Epoch 3/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.5313 - loss: 0.6944 - val_accuracy: 0.8880 - val_loss: 0.6673\n",
            "Epoch 4/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 5s/step - accuracy: 0.5329 - loss: 0.6901 - val_accuracy: 0.8880 - val_loss: 0.6708\n",
            "Epoch 5/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.5129 - loss: 0.6977 - val_accuracy: 0.3920 - val_loss: 0.6915\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.3953 - loss: 0.6923\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step\n",
            "Threshold 0.10 → F1 Score: 0.9407\n",
            "Threshold 0.20 → F1 Score: 0.9407\n",
            "Threshold 0.30 → F1 Score: 0.9407\n",
            "Threshold 0.40 → F1 Score: 0.9407\n",
            "Threshold 0.50 → F1 Score: 0.5065\n",
            "Threshold 0.60 → F1 Score: 0.0000\n",
            "Threshold 0.70 → F1 Score: 0.0000\n",
            "Threshold 0.80 → F1 Score: 0.0000\n",
            "Threshold 0.90 → F1 Score: 0.0000\n",
            "\n",
            "Best Threshold: 0.10 → F1 Score: 0.9407\n",
            "Test Accuracy (train size=500): 39.20%\n",
            "AUC: 0.5373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Plotting all of the different training set sizes so we can just evaluate what a generic classifier is going to be doing in response to training size increase.\n",
        "I will then use this to plot how AUC and accuracy change over the course of the simple classifier.\n",
        "\n",
        "model_350_class, history_350_class, acc_350_class, auc_350_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=350\n",
        ")\n",
        "\n",
        "model_450_class, history_450_class, acc_450_class, auc_450_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=450\n",
        ")\n",
        "\n",
        "model_550_class, history_550_class, acc_550_class, auc_550_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=550\n",
        ")\n",
        "\n",
        "model_650_class, history_650_class, acc_650_class, auc_650_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=650\n",
        ")\n",
        "\n",
        "model_750_class, history_750_class, acc_750_class, auc_750_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=750\n",
        ")\n",
        "\n",
        "model_850_class, history_850_class, acc_850_class, auc_850_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=850\n",
        ")\n",
        "\n",
        "model_950_class, history_950_class, acc_950_class, auc_950_class = train_model_with_class_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=950\n",
        ")"
      ],
      "metadata": {
        "id": "2MkKPqcU2qg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000_class, history_1000_class, acc_1000_class, auc_1000_class = train_model_with_class_weighting(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")"
      ],
      "metadata": {
        "id": "sUj0IHqg3dgR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7000_class, history_7000_class, acc_7000_class, auc_7000_class = train_model_with_class_weighting(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=7000\n",
        ")"
      ],
      "metadata": {
        "id": "aFW6e1tOEHjb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_noise(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=5,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/results_noise\"):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    # Sample training and test subsets\n",
        "    train_metadata_subset = train_metadata.sample(train_size, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Save class distributions\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    train_dist = save_distribution(train_metadata_subset, \"train\")\n",
        "    test_dist = save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Combined barplot\n",
        "    combined_df = pd.concat([\n",
        "        train_dist[\"Percent\"].rename(\"Train\"),\n",
        "        test_dist[\"Percent\"].rename(\"Test\")\n",
        "    ], axis=1).fillna(0).reset_index()\n",
        "\n",
        "    # Rename the correct column to 'Label'\n",
        "    combined_df.columns.values[0] = \"Label\"\n",
        "\n",
        "    combined_df = pd.melt(combined_df, id_vars=\"Label\", var_name=\"Set\", value_name=\"Percent\")\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(data=combined_df, x=\"Label\", y=\"Percent\", hue=\"Set\")\n",
        "    plt.title(\"Class Distribution: Train vs Test\")\n",
        "    plt.ylabel(\"Percentage\")\n",
        "    plt.xlabel(\"Class Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{result_prefix}_class_distribution_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    # Data generators with noisey training set\n",
        "    train_datagen_noisy = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.15,\n",
        "        height_shift_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range=[0.8, 1.2],\n",
        "        zoom_range=0.1,\n",
        "        preprocessing_function=lambda x: x + np.random.normal(loc=0.0, scale=0.05, size=x.shape)\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # CNN model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    import numpy as np\n",
        "\n",
        "    # Map labels to integers using the generator's class indices\n",
        "    label_map = train_generator.class_indices\n",
        "    inv_label_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "    # Convert y labels to 0/1\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"].map(label_map)\n",
        "\n",
        "    # Compute class weights\n",
        "    # class_weights = compute_class_weight(\n",
        "    #     class_weight=\"balanced\",\n",
        "    #     classes=np.unique(y_train_labels),\n",
        "    #     y=y_train_labels\n",
        "    # )\n",
        "    # class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=1\n",
        "        # class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    y_true = test_generator.classes\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Save confusion matrix\n",
        "    confusion_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[\"Mass\", \"No Finding\"],\n",
        "    columns=[\"Predicted Mass\", \"Predicted No Finding\"])\n",
        "\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    # Save predictions\n",
        "    filenames = test_generator.filenames\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": y_pred,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    # Save ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc"
      ],
      "metadata": {
        "id": "8gfTzrG9PQqX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_250, history_250, acc_250, auc_250 = train_model_with_noise(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=250\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jaWelBSso7X",
        "outputId": "dc150ab6-547a-478b-cc49-d8ce2bbcb7b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 250 validated image filenames belonging to 2 classes.\n",
            "Found 62 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 14s/step - accuracy: 0.8507 - loss: 1.5540 - val_accuracy: 0.8548 - val_loss: 0.4187\n",
            "Epoch 2/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 7s/step - accuracy: 0.9391 - loss: 0.2866 - val_accuracy: 0.8548 - val_loss: 0.4984\n",
            "Epoch 3/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5s/step - accuracy: 0.9390 - loss: 0.2459 - val_accuracy: 0.8548 - val_loss: 0.4411\n",
            "Epoch 4/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6s/step - accuracy: 0.9403 - loss: 0.2539 - val_accuracy: 0.8548 - val_loss: 0.4379\n",
            "Epoch 5/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 7s/step - accuracy: 0.9226 - loss: 0.2831 - val_accuracy: 0.8548 - val_loss: 0.4618\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 946ms/step - accuracy: 0.8303 - loss: 0.5247\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step\n",
            "Test Accuracy (train size=250): 85.48%\n",
            "AUC: 0.4906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_500, history_500, acc_500, auc_500 = train_model_with_noise(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=500\n",
        ")"
      ],
      "metadata": {
        "id": "ejdC5X1lsu5S"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000, history_1000, acc_1000, auc_1000 = train_model_with_noise(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")"
      ],
      "metadata": {
        "id": "YDbv-HtAswHn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nothing seems to be working, our dataset is preventing our model from being able to distinguish between classes well, and the addition of guassian noise almost appears to have little effect becuase the model's classification is already so poor."
      ],
      "metadata": {
        "id": "ahE5lyn3jiLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us see if we can distinguish between different types of Mass, rather than distinguishing between No Finding\n",
        "metadata_path = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/Data_Entry_2017_v2020.csv\"\n",
        "image_folder = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/images\"\n",
        "\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(\"Metdata loaded\")\n",
        "\n",
        "# Filtering the metadata to find images labeled either no finding or those containing the word mass\n",
        "filtered_metadata = metadata[\n",
        "    (metadata[\"Finding Labels\"] == \"No Finding\") |\n",
        "    (metadata[\"Finding Labels\"].str.contains(\"Mass\", na=False))\n",
        "]\n",
        "\n",
        "filtered_image_indexes = set(filtered_metadata[\"Image Index\"])\n",
        "filtered_metadata = filtered_metadata.head(50000)\n",
        "\n",
        "matching_images = sorted(list(filtered_metadata[\"Image Index\"]))\n",
        "\n",
        "# Convert to stored list\n",
        "matching_images = sorted(list(matching_images))\n",
        "\n",
        "print(f\"Total matching images found: {len(matching_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5PHR-cL6rph",
        "outputId": "3e28df65-bc1f-45f8-c8ca-4c2c16bb2611"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metdata loaded\n",
            "Total matching images found: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        " # Check class distribution before splitting\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n",
        "\n",
        "# There are many small classes of mass, so need to group them all together before splitting\n",
        "# Standardize labels: Converting anything containing \"Mass\" to just \"Mass\"\n",
        "filtered_metadata[\"Finding Labels\"] = filtered_metadata[\"Finding Labels\"].apply(\n",
        "    lambda x: \"Edema\" if \"Edema\" in x else x\n",
        ")\n",
        "\n",
        "filtered_metadata[\"Finding Labels\"] = filtered_metadata[\"Finding Labels\"].apply(\n",
        "    lambda x: \"Cardiomegaly\" if \"Cardiomegaly\" in x else x\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klGk-o6y388P",
        "outputId": "3638f772-7ead-4e64-e87c-463a978f6f3e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding Labels\n",
            "No Finding                                                                          45542\n",
            "Mass                                                                                 1708\n",
            "Infiltration|Mass                                                                     329\n",
            "Mass|Nodule                                                                           293\n",
            "Effusion|Mass                                                                         285\n",
            "                                                                                    ...  \n",
            "Effusion|Emphysema|Mass|Nodule                                                          1\n",
            "Atelectasis|Consolidation|Effusion|Fibrosis|Infiltration|Mass|Pleural_Thickening        1\n",
            "Atelectasis|Consolidation|Effusion|Fibrosis|Infiltration|Mass                           1\n",
            "Cardiomegaly|Consolidation|Effusion|Infiltration|Mass|Nodule                            1\n",
            "Edema|Fibrosis|Infiltration|Mass                                                        1\n",
            "Name: count, Length: 258, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_metadata[\"Finding Labels\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1JOlvoV60MY",
        "outputId": "505e42ef-db6f-4fc4-8ced-61d35cc64d16"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding Labels\n",
            "No Finding                                                    45542\n",
            "Mass                                                           1708\n",
            "Infiltration|Mass                                               329\n",
            "Mass|Nodule                                                     293\n",
            "Effusion|Mass                                                   285\n",
            "                                                              ...  \n",
            "Effusion|Infiltration|Mass|Pleural_Thickening|Pneumothorax        1\n",
            "Mass|Nodule|Atelectasis                                           1\n",
            "Infiltration|Mass|Pleural_Thickening|Pneumothorax                 1\n",
            "Effusion|Nodule|Pneumothorax|Mass                                 1\n",
            "Infiltration|Mass|Nodule|Pneumonia                                1\n",
            "Name: count, Length: 191, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now try to distinguish between Cardiomegaly and Edema"
      ],
      "metadata": {
        "id": "z_9qRRKs4NRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\"Cardiomegaly\": 0, \"Edema\": 1}\n",
        "filtered_metadata[\"Label\"] = filtered_metadata[\"Finding Labels\"].map(label_map)"
      ],
      "metadata": {
        "id": "CbKnJZpF4hHP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_metadata[\"Label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afoGjs9s68gj",
        "outputId": "338a74d3-2bc8-4364-ca59-718d454a7e29"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3       NaN\n",
            "12      NaN\n",
            "13      NaN\n",
            "14      NaN\n",
            "15      NaN\n",
            "         ..\n",
            "83732   NaN\n",
            "83734   NaN\n",
            "83735   NaN\n",
            "83736   NaN\n",
            "83737   NaN\n",
            "Name: Label, Length: 50000, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_metadata = filtered_metadata[filtered_metadata['Label'].notna()]"
      ],
      "metadata": {
        "id": "eZ98cF668B_F"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "x_2m5tVv7GMM",
        "outputId": "9c7a9d8e-2f4a-4e65-a47f-8b0a66e654ca"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
              "41     00000013_025.png   Cardiomegaly            3          13           56   \n",
              "43     00000013_027.png   Cardiomegaly            5          13           56   \n",
              "44     00000013_028.png   Cardiomegaly            6          13           56   \n",
              "45     00000013_029.png   Cardiomegaly            7          13           56   \n",
              "46     00000013_030.png   Cardiomegaly            8          13           56   \n",
              "...                 ...            ...          ...         ...          ...   \n",
              "82776  00020333_001.png          Edema            1       20333           64   \n",
              "82784  00020337_000.png   Cardiomegaly            0       20337           53   \n",
              "82851  00020363_000.png   Cardiomegaly            0       20363           36   \n",
              "82934  00020396_001.png          Edema            1       20396           41   \n",
              "83161  00020429_009.png   Cardiomegaly            9       20429           59   \n",
              "\n",
              "      Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
              "41                 M            PA                 2992     2991   \n",
              "43                 M            AP                 2500     2048   \n",
              "44                 M            AP                 2500     2048   \n",
              "45                 M            AP                 2500     2048   \n",
              "46                 M            AP                 2500     2048   \n",
              "...              ...           ...                  ...      ...   \n",
              "82776              F            AP                 3056     2544   \n",
              "82784              M            PA                 2922     2991   \n",
              "82851              F            PA                 2544     2916   \n",
              "82934              M            PA                 2544     3040   \n",
              "83161              M            AP                 3056     2544   \n",
              "\n",
              "       OriginalImagePixelSpacing[x     y]  Label  \n",
              "41                           0.143  0.143    0.0  \n",
              "43                           0.168  0.168    0.0  \n",
              "44                           0.168  0.168    0.0  \n",
              "45                           0.168  0.168    0.0  \n",
              "46                           0.168  0.168    0.0  \n",
              "...                            ...    ...    ...  \n",
              "82776                        0.139  0.139    1.0  \n",
              "82784                        0.143  0.143    0.0  \n",
              "82851                        0.139  0.139    0.0  \n",
              "82934                        0.139  0.139    1.0  \n",
              "83161                        0.139  0.139    0.0  \n",
              "\n",
              "[171 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f009d316-8d70-45e1-a328-53fd4927bbff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>y]</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>00000013_025.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>56</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2992</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>00000013_027.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>56</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>00000013_028.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>56</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>00000013_029.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>56</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>00000013_030.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>56</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82776</th>\n",
              "      <td>00020333_001.png</td>\n",
              "      <td>Edema</td>\n",
              "      <td>1</td>\n",
              "      <td>20333</td>\n",
              "      <td>64</td>\n",
              "      <td>F</td>\n",
              "      <td>AP</td>\n",
              "      <td>3056</td>\n",
              "      <td>2544</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.139</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82784</th>\n",
              "      <td>00020337_000.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>0</td>\n",
              "      <td>20337</td>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2922</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82851</th>\n",
              "      <td>00020363_000.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>0</td>\n",
              "      <td>20363</td>\n",
              "      <td>36</td>\n",
              "      <td>F</td>\n",
              "      <td>PA</td>\n",
              "      <td>2544</td>\n",
              "      <td>2916</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82934</th>\n",
              "      <td>00020396_001.png</td>\n",
              "      <td>Edema</td>\n",
              "      <td>1</td>\n",
              "      <td>20396</td>\n",
              "      <td>41</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2544</td>\n",
              "      <td>3040</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.139</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83161</th>\n",
              "      <td>00020429_009.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>9</td>\n",
              "      <td>20429</td>\n",
              "      <td>59</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>3056</td>\n",
              "      <td>2544</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>171 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f009d316-8d70-45e1-a328-53fd4927bbff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f009d316-8d70-45e1-a328-53fd4927bbff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f009d316-8d70-45e1-a328-53fd4927bbff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aba6eecc-f07e-4616-82cb-e1fe14d10fe0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aba6eecc-f07e-4616-82cb-e1fe14d10fe0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aba6eecc-f07e-4616-82cb-e1fe14d10fe0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2676b8b0-beac-4efe-b31b-37a76277499f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('filtered_metadata')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2676b8b0-beac-4efe-b31b-37a76277499f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('filtered_metadata');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_metadata",
              "summary": "{\n  \"name\": \"filtered_metadata\",\n  \"rows\": 171,\n  \"fields\": [\n    {\n      \"column\": \"Image Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 171,\n        \"samples\": [\n          \"00016564_000.png\",\n          \"00010314_015.png\",\n          \"00010314_016.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Finding Labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Edema\",\n          \"Cardiomegaly\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Follow-up #\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 67,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          48,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6005,\n        \"min\": 13,\n        \"max\": 20429,\n        \"num_unique_values\": 128,\n        \"samples\": [\n          13648,\n          10427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 3,\n        \"max\": 81,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          56,\n          57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"F\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"View Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"AP\",\n          \"PA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalImage[Width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272,\n        \"min\": 2021,\n        \"max\": 3056,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          2670,\n          2480\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 394,\n        \"min\": 1832,\n        \"max\": 3056,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          2529,\n          1832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalImagePixelSpacing[x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013058273404993994,\n        \"min\": 0.139,\n        \"max\": 0.1943109999999999,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.168,\n          0.139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y]\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013058273404993994,\n        \"min\": 0.139,\n        \"max\": 0.1943109999999999,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.168,\n          0.139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4895888912360457,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data while ensuring proportional distribution of classes\n",
        "train_metadata, test_metadata = train_test_split(\n",
        "    filtered_metadata,\n",
        "    test_size=0.2,\n",
        "    stratify=filtered_metadata[\"Label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Class distribution in train and test sets\n",
        "print(\"Training set:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"Testing Set:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB9idhGT6KuX",
        "outputId": "14e72b1c-4de5-4b90-f169-91607705da7a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Label\n",
            "1.0    83\n",
            "0.0    53\n",
            "Name: count, dtype: int64\n",
            "Testing Set:\n",
            "Label\n",
            "1.0    21\n",
            "0.0    14\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering metdata for new approach\n",
        "train_image_files = set(train_metadata[\"Image Index\"])\n",
        "test_image_files = set(test_metadata[\"Image Index\"])\n",
        "\n",
        "train_images = sorted(list(train_image_files))\n",
        "test_images = sorted(list(test_image_files))\n",
        "\n",
        "# Convert to sorted lists\n",
        "train_images = sorted(list(train_images))\n",
        "test_images = sorted(list(test_images))\n",
        "\n",
        "\n",
        "print(f\"Total train images found: {len(train_images)}\")\n",
        "print(f\"Total test images found: {len(test_images)}\")\n",
        "\n",
        "# Print a few samples\n",
        "print(\"Sample train images:\", train_images[:10])\n",
        "print(\"Sample test images:\", test_images[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT_1sFoa6QiN",
        "outputId": "be4500a2-040c-4ab1-90c4-43e20d5cd44b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images found: 136\n",
            "Total test images found: 35\n",
            "Sample train images: ['00000013_025.png', '00000013_027.png', '00000013_028.png', '00000013_029.png', '00000013_030.png', '00000013_044.png', '00000211_035.png', '00000376_008.png', '00000435_000.png', '00001097_000.png']\n",
            "Sample test images: ['00001301_044.png', '00004746_003.png', '00006829_007.png', '00006829_008.png', '00007872_003.png', '00008613_007.png', '00009608_023.png', '00009640_003.png', '00010294_048.png', '00010314_016.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing parameters\n",
        "image_size = (224, 224)  # Resize images\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Normalize pixel values\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "\n",
        "# Only rescale for testing\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load train images from directory\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")\n",
        "\n",
        "# Load test images\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BwRot1c6TKR",
        "outputId": "8fcfcead-e784-4e7c-cd1a-392b12dbe407"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 136 validated image filenames.\n",
            "Found 35 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_metadata[\"Finding Labels\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOKMYKqyAMNK",
        "outputId": "27cab108-29fe-4622-a540-6d5946c6614c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding Labels\n",
            "Edema           83\n",
            "Cardiomegaly    53\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_subset(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=5,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/results\"):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    import numpy as np\n",
        "\n",
        "    # Sample training and test subsets\n",
        "    train_metadata_subset = train_metadata.sample(train_size, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    # Filter to only Edema and Cardiomegaly\n",
        "    allowed_labels = [\"Edema\", \"Cardiomegaly\"]\n",
        "    train_metadata_subset = train_metadata_subset[train_metadata_subset[\"Finding Labels\"].isin(allowed_labels)]\n",
        "    test_metadata_subset = test_metadata_subset[test_metadata_subset[\"Finding Labels\"].isin(allowed_labels)]\n",
        "\n",
        "    # # Map labels: Edema -> 1, Cardiomegaly -> 0\n",
        "    # label_map = {\"Cardiomegaly\": 0, \"Edema\": 1}\n",
        "    # train_metadata_subset[\"Finding Labels\"] = train_metadata_subset[\"Finding Labels\"].map(label_map)\n",
        "    # test_metadata_subset[\"Finding Labels\"] = test_metadata_subset[\"Finding Labels\"].map(label_map)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Save class distributions\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    train_dist = save_distribution(train_metadata_subset, \"train\")\n",
        "    test_dist = save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Combined barplot\n",
        "    combined_df = pd.concat([\n",
        "        train_dist[\"Percent\"].rename(\"Train\"),\n",
        "        test_dist[\"Percent\"].rename(\"Test\")\n",
        "    ], axis=1).fillna(0).reset_index()\n",
        "\n",
        "    combined_df.columns.values[0] = \"Label\"\n",
        "    combined_df = pd.melt(combined_df, id_vars=\"Label\", var_name=\"Set\", value_name=\"Percent\")\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(data=combined_df, x=\"Label\", y=\"Percent\", hue=\"Set\")\n",
        "    plt.title(\"Class Distribution: Train vs Test\")\n",
        "    plt.ylabel(\"Percentage\")\n",
        "    plt.xlabel(\"Class Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{result_prefix}_class_distribution_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Image data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # CNN model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"]\n",
        "    classes = np.unique(y_train_labels)  # ['Cardiomegaly' 'Edema']\n",
        "\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=classes,\n",
        "        y=y_train_labels\n",
        "    )\n",
        "    class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "    print(\"Class weights:\", class_weight_dict)\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "    y_true = test_generator.classes\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Save confusion matrix\n",
        "    confusion_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Cardiomegaly (0)\", \"Edema (1)\"],\n",
        "        columns=[\"Predicted Cardiomegaly (0)\", \"Predicted Edema (1)\"]\n",
        "    )\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    # Save predictions\n",
        "    filenames = test_generator.filenames\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": y_pred,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    # Save ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc"
      ],
      "metadata": {
        "id": "SA8uuKyt6EmV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_small, history_small, acc_small, auc_small = train_model_with_subset(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=136\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUtO5YfY8urf",
        "outputId": "faad9ca2-a279-41ea-9bf5-0b6c2114d0d4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 136 validated image filenames belonging to 2 classes.\n",
            "Found 34 validated image filenames belonging to 2 classes.\n",
            "Class weights: {'Cardiomegaly': np.float64(1.2830188679245282), 'Edema': np.float64(0.8192771084337349)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4s/step - accuracy: 0.6218 - loss: 2.0099 - val_accuracy: 0.3824 - val_loss: 0.7250\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4s/step - accuracy: 0.5384 - loss: 0.6959 - val_accuracy: 0.6176 - val_loss: 0.6748\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.6072 - loss: 0.6987 - val_accuracy: 0.6176 - val_loss: 0.6716\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5s/step - accuracy: 0.6194 - loss: 0.6729 - val_accuracy: 0.6176 - val_loss: 0.6813\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.5787 - loss: 0.6871 - val_accuracy: 0.6176 - val_loss: 0.6862\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.6201 - loss: 0.6860\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step\n",
            "Test Accuracy (train size=136): 61.76%\n",
            "AUC: 0.4579\n"
          ]
        }
      ]
    }
  ]
}