{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdiVM/Neuro240/blob/main/AM_Neuro240_FinalProject_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code for my final assignment. Note that for ease and readability, all my previous code is available with its respective checkpoints here: https://github.com/AdiVM/Neuro240\n",
        "\n",
        "Much of my code was written for these checkpoints, and rather than submit it all again as one ipynb, I have just uploaded the respective code to github."
      ],
      "metadata": {
        "id": "kHCn6PnUOk3g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_PdcJlQyDlD",
        "outputId": "a00ecdcf-15c5-420d-89ba-f6ba458ee384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# All future runs can start here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8-T_YFvyEpR",
        "outputId": "d12f9bef-5b01-45d8-9ad8-5ac0c4d30bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metdata loaded\n",
            "Total matching images found: 50000\n"
          ]
        }
      ],
      "source": [
        "metadata_path = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/Data_Entry_2017_v2020.csv\"\n",
        "image_folder = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/images\"\n",
        "\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(\"Metdata loaded\")\n",
        "\n",
        "# Filtering the metadata to find images labeled either no finding or those containing the word mass\n",
        "filtered_metadata = metadata[\n",
        "    (metadata[\"Finding Labels\"] == \"No Finding\") |\n",
        "    (metadata[\"Finding Labels\"].str.contains(\"Mass\", na=False))\n",
        "]\n",
        "\n",
        "filtered_image_indexes = set(filtered_metadata[\"Image Index\"])\n",
        "filtered_metadata = filtered_metadata.head(50000)\n",
        "\n",
        "matching_images = sorted(list(filtered_metadata[\"Image Index\"]))\n",
        "\n",
        "# Convert to stored list\n",
        "matching_images = sorted(list(matching_images))\n",
        "\n",
        "print(f\"Total matching images found: {len(matching_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xKqoPmUyLE-",
        "outputId": "8cde163e-d0a2-4291-9404-517d837df174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding Labels\n",
            "No Finding                                                            45542\n",
            "Mass                                                                   1708\n",
            "Infiltration|Mass                                                       329\n",
            "Mass|Nodule                                                             293\n",
            "Effusion|Mass                                                           285\n",
            "                                                                      ...  \n",
            "Atelectasis|Cardiomegaly|Consolidation|Effusion|Mass|Nodule               1\n",
            "Atelectasis|Consolidation|Effusion|Mass|Nodule|Pleural_Thickening         1\n",
            "Cardiomegaly|Consolidation|Effusion|Mass|Nodule|Pleural_Thickening        1\n",
            "Cardiomegaly|Consolidation|Effusion|Infiltration|Mass|Nodule              1\n",
            "Edema|Fibrosis|Infiltration|Mass                                          1\n",
            "Name: count, Length: 258, dtype: int64\n",
            "Finding Labels\n",
            "No Finding    45542\n",
            "Mass           4458\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Now to perform stratified shuffle split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        " # Check class distribution before splitting\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n",
        "\n",
        "# There are many small classes of mass, so need to group them all together before splitting\n",
        "# Standardize labels: Convert anything containing \"Mass\" to just \"Mass\"\n",
        "filtered_metadata[\"Finding Labels\"] = filtered_metadata[\"Finding Labels\"].apply(\n",
        "    lambda x: \"Mass\" if \"Mass\" in x else x\n",
        ")\n",
        "\n",
        "# Verify new label counts\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxHdem9r6Ewk"
      },
      "outputs": [],
      "source": [
        "label_map = {\"No Finding\": 0, \"Mass\": 1}\n",
        "filtered_metadata[\"Label\"] = filtered_metadata[\"Finding Labels\"].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xripsguQyPqP",
        "outputId": "ec688fe7-44d8-4c51-b5ba-5ea324583f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Label\n",
            "0    36434\n",
            "1     3566\n",
            "Name: count, dtype: int64\n",
            "Testing Set:\n",
            "Label\n",
            "0    9108\n",
            "1     892\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Split the data while ensuring proportional distribution of classes\n",
        "train_metadata, test_metadata = train_test_split(\n",
        "    filtered_metadata,\n",
        "    test_size=0.2,\n",
        "    stratify=filtered_metadata[\"Label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Class distribution in train and test sets\n",
        "print(\"Training set:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"Testing Set:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6h6-YhWySET",
        "outputId": "5e9a49d4-e5cb-4a6b-932e-4dbf653b986c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train metadata entries: 40000\n",
            "Test metadata entries: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train metadata entries: {len(train_metadata)}\")\n",
        "print(f\"Test metadata entries: {len(test_metadata)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-cLJqxySmw",
        "outputId": "418168eb-e24f-49e0-ff2f-667f181ea6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images found: 40000\n",
            "Total test images found: 10000\n",
            "Sample train images: ['00000002_000.png', '00000004_000.png', '00000005_000.png', '00000005_002.png', '00000005_003.png', '00000005_004.png', '00000005_005.png', '00000006_000.png', '00000007_000.png', '00000011_002.png']\n",
            "Sample test images: ['00000005_001.png', '00000008_001.png', '00000011_001.png', '00000011_003.png', '00000013_000.png', '00000013_017.png', '00000013_029.png', '00000013_030.png', '00000018_000.png', '00000032_049.png']\n"
          ]
        }
      ],
      "source": [
        "# Filtering metdata\n",
        "# Convert \"Image Index\" column to a set for fast lookup\n",
        "train_image_files = set(train_metadata[\"Image Index\"])\n",
        "test_image_files = set(test_metadata[\"Image Index\"])\n",
        "\n",
        "train_images = sorted(list(train_image_files))\n",
        "test_images = sorted(list(test_image_files))\n",
        "\n",
        "# Convert to sorted lists for consistency\n",
        "train_images = sorted(list(train_images))\n",
        "test_images = sorted(list(test_images))\n",
        "\n",
        "\n",
        "print(f\"Total train images found: {len(train_images)}\")\n",
        "print(f\"Total test images found: {len(test_images)}\")\n",
        "\n",
        "# Print a few samples\n",
        "print(\"Sample train images:\", train_images[:10])\n",
        "print(\"Sample test images:\", test_images[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSullbIDyWwk"
      },
      "outputs": [],
      "source": [
        "# I will use TensorFlow for model training\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaTNWs9lyY6O",
        "outputId": "ac0e1028-9681-4364-ab65-650f574dfd9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39997 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3 invalid image filename(s) in x_col=\"Image Index\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "# Image preprocessing parameters\n",
        "image_size = (224, 224)  # Resize images\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Normalize pixel values\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Only rescale for testing\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load train images from directory\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")\n",
        "\n",
        "# Load test images\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lApFIyKt6dYr",
        "outputId": "326aedff-aac9-4a20-da16-386eee0bd984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train distribution:\n",
            "Label\n",
            "0    36434\n",
            "1     3566\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test distribution:\n",
            "Label\n",
            "0    9108\n",
            "1     892\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Train distribution:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"\\nTest distribution:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What follows is a key contributution since the Almost There checkpoint."
      ],
      "metadata": {
        "id": "Pavnn1goPdjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We89N-5FJo92"
      },
      "outputs": [],
      "source": [
        "# This is my key function. I use 100 epochs for much better performance, a perfectly balanced class distribtuion within the training set (50& control, 50% mass -- not the classweighting\n",
        "# equation I previously used) implement early stopping for efficiency, and evaluate savling loss and accuracy curves.\n",
        "\n",
        "def train_model_with_class_weighting(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=100,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/final_results\"):\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from tensorflow.keras.callbacks import EarlyStopping\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Sample balanced subset\n",
        "    half_size = train_size // 2\n",
        "    mass_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"Mass\"].sample(half_size, random_state=42)\n",
        "    no_finding_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"No Finding\"].sample(half_size, random_state=42)\n",
        "    train_metadata_subset = pd.concat([mass_subset, no_finding_subset]).sample(frac=1, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    # Save class distribution\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    save_distribution(train_metadata_subset, \"train\")\n",
        "    save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Class weights\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"]\n",
        "    classes = np.unique(y_train_labels)\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_labels)\n",
        "    class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "    # Old Sequential Model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save loss & accuracy curves\n",
        "    pd.DataFrame(history.history).to_csv(f\"{result_prefix}_training_history.csv\", index=False)\n",
        "    for metric in ['loss', 'accuracy']:\n",
        "        plt.figure()\n",
        "        plt.plot(history.history[metric], label='Train')\n",
        "        plt.plot(history.history[f'val_{metric}'], label='Validation')\n",
        "        plt.title(f'{metric.capitalize()} over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f\"{result_prefix}_{metric}_curve.png\")\n",
        "        plt.close()\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    thresholds = np.linspace(0.1, 0.9, 9)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_preds = None\n",
        "\n",
        "    for t in thresholds:\n",
        "        preds = (y_pred_proba > t).astype(int)\n",
        "        f1 = f1_score(y_true, preds)\n",
        "        print(f\"Threshold {t:.2f} → F1 Score: {f1:.4f}\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = t\n",
        "            best_preds = preds\n",
        "\n",
        "    print(f\"\\nBest Threshold: {best_threshold:.2f} → F1 Score: {best_f1:.4f}\")\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, best_preds)\n",
        "\n",
        "    confusion_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Mass\", \"No Finding\"],\n",
        "        columns=[\"Predicted Mass\", \"Predicted No Finding\"]\n",
        "    )\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": test_generator.filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": best_preds,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    with open(f\"{result_prefix}_best_threshold.txt\", \"w\") as f:\n",
        "        f.write(f\"Best threshold: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc, result_prefix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking results without early stopping\n",
        "def train_model_with_class_weighting_nostop(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=100,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/final_results/nostop\"):\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    from tensorflow.keras import Input, Model\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Sample balanced subset\n",
        "    half_size = train_size // 2\n",
        "    mass_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"Mass\"].sample(half_size, random_state=42)\n",
        "    no_finding_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"No Finding\"].sample(half_size, random_state=42)\n",
        "    train_metadata_subset = pd.concat([mass_subset, no_finding_subset]).sample(frac=1, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    # Save class distribution\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    save_distribution(train_metadata_subset, \"train\")\n",
        "    save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Class weights\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"]\n",
        "    classes = np.unique(y_train_labels)\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_labels)\n",
        "    class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "    # Model\n",
        "    # # Old Sequential Model\n",
        "    # model = Sequential([\n",
        "    #     Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "    #     MaxPooling2D(pool_size=(2, 2)),\n",
        "    #     Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    #     MaxPooling2D(pool_size=(2, 2)),\n",
        "    #     Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    #     MaxPooling2D(pool_size=(2, 2)),\n",
        "    #     Flatten(),\n",
        "    #     Dense(128, activation=\"relu\"),\n",
        "    #     Dropout(0.5),\n",
        "    #     Dense(1, activation=\"sigmoid\")\n",
        "    # ])\n",
        "\n",
        "    # I will have to try a functional API model, doing this for Grad-CAM\n",
        "\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    x = Conv2D(32, (3, 3), activation=\"relu\")(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    # Rest of code continues as normal\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save loss & accuracy curves\n",
        "    pd.DataFrame(history.history).to_csv(f\"{result_prefix}_training_history.csv\", index=False)\n",
        "    for metric in ['loss', 'accuracy']:\n",
        "        plt.figure()\n",
        "        plt.plot(history.history[metric], label='Train')\n",
        "        plt.plot(history.history[f'val_{metric}'], label='Validation')\n",
        "        plt.title(f'{metric.capitalize()} over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f\"{result_prefix}_{metric}_curve.png\")\n",
        "        plt.close()\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    thresholds = np.linspace(0.1, 0.9, 9)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_preds = None\n",
        "\n",
        "    for t in thresholds:\n",
        "        preds = (y_pred_proba > t).astype(int)\n",
        "        f1 = f1_score(y_true, preds)\n",
        "        print(f\"Threshold {t:.2f} → F1 Score: {f1:.4f}\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = t\n",
        "            best_preds = preds\n",
        "\n",
        "    print(f\"\\nBest Threshold: {best_threshold:.2f} → F1 Score: {best_f1:.4f}\")\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, best_preds)\n",
        "\n",
        "    confusion_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Mass\", \"No Finding\"],\n",
        "        columns=[\"Predicted Mass\", \"Predicted No Finding\"]\n",
        "    )\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": test_generator.filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": best_preds,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    with open(f\"{result_prefix}_best_threshold.txt\", \"w\") as f:\n",
        "        f.write(f\"Best threshold: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc, result_prefix"
      ],
      "metadata": {
        "id": "ZQrwWIjqXohC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9HfxrncMS0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57f1f08-9130-4156-f524-da85ec41983c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 validated image filenames belonging to 2 classes.\n",
            "Found 250 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 21s/step - accuracy: 0.4569 - loss: 0.8497 - val_accuracy: 0.9200 - val_loss: 0.6745\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4646 - loss: 0.6946 - val_accuracy: 0.1160 - val_loss: 0.6952\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.4942 - loss: 0.6930 - val_accuracy: 0.9200 - val_loss: 0.5940\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4765 - loss: 0.7018 - val_accuracy: 0.0920 - val_loss: 0.7465\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5140 - loss: 0.6929 - val_accuracy: 0.1000 - val_loss: 0.7041\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5006 - loss: 0.6948 - val_accuracy: 0.8000 - val_loss: 0.6629\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5077 - loss: 0.6952 - val_accuracy: 0.5400 - val_loss: 0.7179\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5348 - loss: 0.6912 - val_accuracy: 0.5400 - val_loss: 0.7299\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5070 - loss: 0.6942 - val_accuracy: 0.4560 - val_loss: 0.7112\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5233 - loss: 0.6932 - val_accuracy: 0.1760 - val_loss: 0.7038\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5214 - loss: 0.6908 - val_accuracy: 0.6000 - val_loss: 0.7013\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.4835 - loss: 0.6919 - val_accuracy: 0.1520 - val_loss: 0.7283\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4915 - loss: 0.6896 - val_accuracy: 0.1640 - val_loss: 0.7094\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5431 - loss: 0.6921 - val_accuracy: 0.5560 - val_loss: 0.7046\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5282 - loss: 0.6910 - val_accuracy: 0.3280 - val_loss: 0.7254\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5346 - loss: 0.6933 - val_accuracy: 0.2200 - val_loss: 0.7110\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5271 - loss: 0.6910 - val_accuracy: 0.2920 - val_loss: 0.7224\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5230 - loss: 0.6918 - val_accuracy: 0.3920 - val_loss: 0.7126\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5481 - loss: 0.6892 - val_accuracy: 0.3680 - val_loss: 0.7205\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5156 - loss: 0.6912 - val_accuracy: 0.7880 - val_loss: 0.6349\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5304 - loss: 0.6897 - val_accuracy: 0.1840 - val_loss: 0.7341\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5173 - loss: 0.6934 - val_accuracy: 0.0880 - val_loss: 0.9188\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4801 - loss: 0.7127 - val_accuracy: 0.6000 - val_loss: 0.7046\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5413 - loss: 0.6907 - val_accuracy: 0.4640 - val_loss: 0.7126\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5460 - loss: 0.6854 - val_accuracy: 0.6200 - val_loss: 0.6874\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5219 - loss: 0.6943 - val_accuracy: 0.3960 - val_loss: 0.7100\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5433 - loss: 0.6880 - val_accuracy: 0.2280 - val_loss: 0.7456\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5371 - loss: 0.6888 - val_accuracy: 0.5560 - val_loss: 0.7176\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5419 - loss: 0.6830 - val_accuracy: 0.4920 - val_loss: 0.7245\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5437 - loss: 0.6851 - val_accuracy: 0.3200 - val_loss: 0.7678\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5454 - loss: 0.6909 - val_accuracy: 0.6320 - val_loss: 0.6823\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5494 - loss: 0.6830 - val_accuracy: 0.5760 - val_loss: 0.6927\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5152 - loss: 0.6887 - val_accuracy: 0.4920 - val_loss: 0.7235\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5378 - loss: 0.6852 - val_accuracy: 0.5760 - val_loss: 0.7080\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5323 - loss: 0.6898 - val_accuracy: 0.3240 - val_loss: 0.7346\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5282 - loss: 0.6894 - val_accuracy: 0.6960 - val_loss: 0.6939\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5512 - loss: 0.6892 - val_accuracy: 0.4280 - val_loss: 0.7595\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5123 - loss: 0.6907 - val_accuracy: 0.4560 - val_loss: 0.7552\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5468 - loss: 0.6872 - val_accuracy: 0.4240 - val_loss: 0.7632\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5233 - loss: 0.6897 - val_accuracy: 0.5240 - val_loss: 0.7229\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5324 - loss: 0.6912 - val_accuracy: 0.4080 - val_loss: 0.7545\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5484 - loss: 0.6855 - val_accuracy: 0.3600 - val_loss: 0.7763\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 0.6800 - val_accuracy: 0.6520 - val_loss: 0.7044\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5297 - loss: 0.6887 - val_accuracy: 0.6560 - val_loss: 0.6967\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5065 - loss: 0.6927 - val_accuracy: 0.5920 - val_loss: 0.7362\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5554 - loss: 0.6853 - val_accuracy: 0.4920 - val_loss: 0.7473\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5447 - loss: 0.6832 - val_accuracy: 0.5920 - val_loss: 0.6851\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5169 - loss: 0.6941 - val_accuracy: 0.4120 - val_loss: 0.7155\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5353 - loss: 0.6899 - val_accuracy: 0.1120 - val_loss: 0.7670\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5070 - loss: 0.6940 - val_accuracy: 0.5240 - val_loss: 0.7126\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5360 - loss: 0.6848 - val_accuracy: 0.4480 - val_loss: 0.7327\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.5778 - loss: 0.6753 - val_accuracy: 0.5080 - val_loss: 0.7170\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5433 - loss: 0.6879 - val_accuracy: 0.2440 - val_loss: 0.7600\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5395 - loss: 0.6876 - val_accuracy: 0.4760 - val_loss: 0.7289\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5385 - loss: 0.6893 - val_accuracy: 0.6320 - val_loss: 0.6724\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5796 - loss: 0.6808 - val_accuracy: 0.4360 - val_loss: 0.7531\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5662 - loss: 0.6718 - val_accuracy: 0.4920 - val_loss: 0.8088\n",
            "Epoch 58/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5387 - loss: 0.6941 - val_accuracy: 0.6240 - val_loss: 0.7139\n",
            "Epoch 59/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5353 - loss: 0.6854 - val_accuracy: 0.5840 - val_loss: 0.7277\n",
            "Epoch 60/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5560 - loss: 0.6793 - val_accuracy: 0.5480 - val_loss: 0.7030\n",
            "Epoch 61/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5524 - loss: 0.6851 - val_accuracy: 0.5520 - val_loss: 0.7261\n",
            "Epoch 62/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5562 - loss: 0.6823 - val_accuracy: 0.4480 - val_loss: 0.7358\n",
            "Epoch 63/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5463 - loss: 0.6790 - val_accuracy: 0.5160 - val_loss: 0.7527\n",
            "Epoch 64/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5475 - loss: 0.6846 - val_accuracy: 0.5800 - val_loss: 0.7045\n",
            "Epoch 65/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.5694 - loss: 0.6763 - val_accuracy: 0.5880 - val_loss: 0.6949\n",
            "Epoch 66/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5460 - loss: 0.6876 - val_accuracy: 0.5640 - val_loss: 0.7080\n",
            "Epoch 67/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5319 - loss: 0.6883 - val_accuracy: 0.5480 - val_loss: 0.7140\n",
            "Epoch 68/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5288 - loss: 0.6807 - val_accuracy: 0.5640 - val_loss: 0.7621\n",
            "Epoch 69/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5747 - loss: 0.6685 - val_accuracy: 0.6080 - val_loss: 0.7001\n",
            "Epoch 70/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5817 - loss: 0.6782 - val_accuracy: 0.6240 - val_loss: 0.6883\n",
            "Epoch 71/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5566 - loss: 0.6770 - val_accuracy: 0.7560 - val_loss: 0.6547\n",
            "Epoch 72/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5528 - loss: 0.6854 - val_accuracy: 0.3400 - val_loss: 0.7968\n",
            "Epoch 73/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5529 - loss: 0.6781 - val_accuracy: 0.6000 - val_loss: 0.6909\n",
            "Epoch 74/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5776 - loss: 0.6760 - val_accuracy: 0.5720 - val_loss: 0.7365\n",
            "Epoch 75/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5460 - loss: 0.6795 - val_accuracy: 0.5440 - val_loss: 0.7120\n",
            "Epoch 76/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5905 - loss: 0.6688 - val_accuracy: 0.5560 - val_loss: 0.7478\n",
            "Epoch 77/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5740 - loss: 0.6723 - val_accuracy: 0.4800 - val_loss: 0.7933\n",
            "Epoch 78/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5795 - loss: 0.6711 - val_accuracy: 0.5760 - val_loss: 0.7359\n",
            "Epoch 79/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - accuracy: 0.5845 - loss: 0.6761 - val_accuracy: 0.6200 - val_loss: 0.7033\n",
            "Epoch 80/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5753 - loss: 0.6724 - val_accuracy: 0.6040 - val_loss: 0.7020\n",
            "Epoch 81/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5995 - loss: 0.6732 - val_accuracy: 0.5480 - val_loss: 0.7144\n",
            "Epoch 82/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5599 - loss: 0.6737 - val_accuracy: 0.7000 - val_loss: 0.6686\n",
            "Epoch 83/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5863 - loss: 0.6709 - val_accuracy: 0.4320 - val_loss: 0.8491\n",
            "Epoch 84/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5754 - loss: 0.6799 - val_accuracy: 0.6440 - val_loss: 0.6987\n",
            "Epoch 85/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5727 - loss: 0.6737 - val_accuracy: 0.6360 - val_loss: 0.7309\n",
            "Epoch 86/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5582 - loss: 0.6758 - val_accuracy: 0.6160 - val_loss: 0.7088\n",
            "Epoch 87/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5868 - loss: 0.6680 - val_accuracy: 0.5200 - val_loss: 0.7447\n",
            "Epoch 88/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5503 - loss: 0.6767 - val_accuracy: 0.5080 - val_loss: 0.7509\n",
            "Epoch 89/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5759 - loss: 0.6716 - val_accuracy: 0.5480 - val_loss: 0.7513\n",
            "Epoch 90/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5758 - loss: 0.6649 - val_accuracy: 0.4560 - val_loss: 0.7834\n",
            "Epoch 91/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5836 - loss: 0.6704 - val_accuracy: 0.6320 - val_loss: 0.6934\n",
            "Epoch 92/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5890 - loss: 0.6744 - val_accuracy: 0.5720 - val_loss: 0.7408\n",
            "Epoch 93/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5649 - loss: 0.6778 - val_accuracy: 0.5440 - val_loss: 0.7295\n",
            "Epoch 94/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6395 - loss: 0.6567 - val_accuracy: 0.6400 - val_loss: 0.7014\n",
            "Epoch 95/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5582 - loss: 0.6740 - val_accuracy: 0.6200 - val_loss: 0.6968\n",
            "Epoch 96/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.5596 - loss: 0.6705 - val_accuracy: 0.5480 - val_loss: 0.7509\n",
            "Epoch 97/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5704 - loss: 0.6722 - val_accuracy: 0.6040 - val_loss: 0.7091\n",
            "Epoch 98/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5799 - loss: 0.6671 - val_accuracy: 0.5920 - val_loss: 0.7432\n",
            "Epoch 99/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5815 - loss: 0.6611 - val_accuracy: 0.6040 - val_loss: 0.7203\n",
            "Epoch 100/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.6001 - loss: 0.6666 - val_accuracy: 0.4920 - val_loss: 0.8000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 621ms/step - accuracy: 0.5015 - loss: 0.8072\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 660ms/step\n",
            "Threshold 0.10 → F1 Score: 0.9518\n",
            "Threshold 0.20 → F1 Score: 0.9379\n",
            "Threshold 0.30 → F1 Score: 0.9079\n",
            "Threshold 0.40 → F1 Score: 0.8157\n",
            "Threshold 0.50 → F1 Score: 0.6382\n",
            "Threshold 0.60 → F1 Score: 0.2930\n",
            "Threshold 0.70 → F1 Score: 0.0506\n",
            "Threshold 0.80 → F1 Score: 0.0086\n",
            "Threshold 0.90 → F1 Score: 0.0000\n",
            "\n",
            "Best Threshold: 0.10 → F1 Score: 0.9518\n",
            "Test Accuracy (train size=1000): 49.20%\n",
            "AUC: 0.5822\n"
          ]
        }
      ],
      "source": [
        "# Training the maximal model since this is the key result to understand for interpretibility I think\n",
        "model_1000_class, history_1000_class, acc_1000_class, auc_1000_class, result_prefix_1000 = train_model_with_class_weighting_nostop(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I also want to just test on the baseline model\n",
        "model_500_class, history_500_class, acc_500_class, auc_500_class, result_prefix_500 = train_model_with_class_weighting_nostop(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=500\n",
        ")\n",
        "\n",
        "# And on the minimal model\n",
        "model_250_class, history_250_class, acc_250_class, auc_250_class, result_prefix_250 = train_model_with_class_weighting_nostop(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=250\n",
        ")"
      ],
      "metadata": {
        "id": "8eUeT9NpqbVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I will perform Grad-CAM Visualization per the encouragement of my TF!\n",
        "def generate_gradcam_visualizations(model, test_generator, results_df, result_prefix,\n",
        "                                    image_folder, num_examples=5):\n",
        "    import tensorflow as tf\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    from tensorflow.keras.preprocessing import image as keras_image\n",
        "    import numpy as np\n",
        "\n",
        "    os.makedirs(f\"{result_prefix}_gradcam\", exist_ok=True)\n",
        "\n",
        "    # Force-build model by passing dummy input (fix for Sequential)\n",
        "    dummy_input = tf.zeros((1, 224, 224, 3))\n",
        "    _ = model(dummy_input)\n",
        "\n",
        "    # Get last convolutional layer name\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            last_conv_layer_name = layer.name\n",
        "            break\n",
        "    else:\n",
        "        raise ValueError(\"No Conv2D layer found in model.\")\n",
        "\n",
        "    # Build Grad-CAM model\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=[model.input],\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Helper to load and preprocess image\n",
        "    def load_image(img_path, target_size):\n",
        "        img = keras_image.load_img(img_path, target_size=target_size)\n",
        "        array = keras_image.img_to_array(img) / 255.0\n",
        "        return np.expand_dims(array, axis=0), img\n",
        "\n",
        "    # Getting indices of false positives and false negatives\n",
        "    fp_idx = results_df[(results_df[\"TrueLabel\"] == 0) & (results_df[\"PredictedLabel\"] == 1)].index\n",
        "    fn_idx = results_df[(results_df[\"TrueLabel\"] == 1) & (results_df[\"PredictedLabel\"] == 0)].index\n",
        "\n",
        "    selected_idx = list(fp_idx[:num_examples]) + list(fn_idx[:num_examples])\n",
        "    selected_type = ['FP'] * min(num_examples, len(fp_idx)) + ['FN'] * min(num_examples, len(fn_idx))\n",
        "\n",
        "    for i, idx in enumerate(selected_idx):\n",
        "        filename = results_df.loc[idx, \"Filename\"]\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img_array, original_img = load_image(img_path, target_size=(224, 224))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            conv_output, predictions = grad_model(img_array)\n",
        "            loss = predictions[:, 0]\n",
        "\n",
        "        grads = tape.gradient(loss, conv_output)\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "        conv_output = conv_output[0]\n",
        "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "\n",
        "        # Normalize and resize\n",
        "        heatmap = np.maximum(heatmap, 0)\n",
        "        heatmap /= np.max(heatmap) + 1e-8\n",
        "        heatmap = cv2.resize(heatmap, (224, 224))\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        superimposed_img = cv2.addWeighted(np.array(original_img).astype(np.uint8), 0.6, heatmap, 0.4, 0)\n",
        "        output_path = os.path.join(result_prefix + \"_gradcam\", f\"{selected_type[i]}_{filename}\")\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    print(f\"Grad-CAM saved for {len(selected_idx)} samples in: {result_prefix}_gradcam\")"
      ],
      "metadata": {
        "id": "eq8pPRGSQJE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Force-build model for Grad-CAM\n",
        "import tensorflow as tf\n",
        "\n",
        "# Build model by passing a real-shape dummy image\n",
        "model_1000_class(tf.zeros((1, 224, 224, 3)))\n",
        "\n",
        "import numpy as np\n",
        "# Now call Grad-CAM\n",
        "results_df = pd.read_csv(f\"{result_prefix_1000}_predictions.csv\")\n",
        "generate_gradcam_visualizations(model_1000_class, test_generator, results_df, result_prefix_1000, image_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBDbGuGIRC7i",
        "outputId": "005bde66-85a7-4150-c539-9af075763a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grad-CAM saved for 8 samples in: /content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/final_results/nostop/train_1000_gradcam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model without early stopping\n",
        "model_1000_class, history_1000_class, acc_1000_class, auc_1000_class, result_prefix_1000 = train_model_with_class_weighting_nostop(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")"
      ],
      "metadata": {
        "id": "DNpaGKuvW8qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d6e048-7d98-4028-c56e-b96b12d6961e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 validated image filenames belonging to 2 classes.\n",
            "Found 250 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5167 - loss: 1.2094 - val_accuracy: 0.9080 - val_loss: 0.6925\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.4991 - loss: 0.6932 - val_accuracy: 0.0960 - val_loss: 0.7007\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5246 - loss: 0.6970 - val_accuracy: 0.6880 - val_loss: 0.6918\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5386 - loss: 0.6940 - val_accuracy: 0.8640 - val_loss: 0.6837\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5309 - loss: 0.6927 - val_accuracy: 0.6400 - val_loss: 0.6920\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5138 - loss: 0.6893 - val_accuracy: 0.6160 - val_loss: 0.6972\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5100 - loss: 0.6928 - val_accuracy: 0.7680 - val_loss: 0.6871\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5170 - loss: 0.6926 - val_accuracy: 0.6920 - val_loss: 0.6900\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5421 - loss: 0.6882 - val_accuracy: 0.5880 - val_loss: 0.7004\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5558 - loss: 0.6895 - val_accuracy: 0.5800 - val_loss: 0.7050\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5464 - loss: 0.6938 - val_accuracy: 0.7760 - val_loss: 0.6856\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5320 - loss: 0.6917 - val_accuracy: 0.5320 - val_loss: 0.7059\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.4909 - loss: 0.6923 - val_accuracy: 0.1880 - val_loss: 0.7037\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5336 - loss: 0.6922 - val_accuracy: 0.2600 - val_loss: 0.6994\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.5358 - loss: 0.6918 - val_accuracy: 0.7880 - val_loss: 0.6773\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5266 - loss: 0.6923 - val_accuracy: 0.5880 - val_loss: 0.6982\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5663 - loss: 0.6882 - val_accuracy: 0.6440 - val_loss: 0.6852\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5471 - loss: 0.6871 - val_accuracy: 0.6640 - val_loss: 0.6841\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5369 - loss: 0.6912 - val_accuracy: 0.4920 - val_loss: 0.7049\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5463 - loss: 0.6926 - val_accuracy: 0.5160 - val_loss: 0.7110\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5205 - loss: 0.6918 - val_accuracy: 0.8120 - val_loss: 0.6562\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5384 - loss: 0.6911 - val_accuracy: 0.6720 - val_loss: 0.6882\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5578 - loss: 0.6863 - val_accuracy: 0.5200 - val_loss: 0.7090\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5260 - loss: 0.6919 - val_accuracy: 0.6640 - val_loss: 0.6803\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5318 - loss: 0.6914 - val_accuracy: 0.6120 - val_loss: 0.6881\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5465 - loss: 0.6827 - val_accuracy: 0.5880 - val_loss: 0.6895\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5474 - loss: 0.6891 - val_accuracy: 0.5320 - val_loss: 0.7138\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.5730 - loss: 0.6833 - val_accuracy: 0.6160 - val_loss: 0.6834\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5226 - loss: 0.7042 - val_accuracy: 0.5760 - val_loss: 0.6987\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5138 - loss: 0.6910 - val_accuracy: 0.6720 - val_loss: 0.6697\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5181 - loss: 0.6940 - val_accuracy: 0.6880 - val_loss: 0.6717\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5546 - loss: 0.6883 - val_accuracy: 0.6240 - val_loss: 0.6847\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5508 - loss: 0.6814 - val_accuracy: 0.5800 - val_loss: 0.6893\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5494 - loss: 0.6920 - val_accuracy: 0.4400 - val_loss: 0.7233\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5200 - loss: 0.6890 - val_accuracy: 0.5880 - val_loss: 0.6919\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5347 - loss: 0.6910 - val_accuracy: 0.5200 - val_loss: 0.7176\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5371 - loss: 0.6833 - val_accuracy: 0.6600 - val_loss: 0.6692\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5454 - loss: 0.6905 - val_accuracy: 0.6560 - val_loss: 0.6791\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5438 - loss: 0.6889 - val_accuracy: 0.6280 - val_loss: 0.6808\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5492 - loss: 0.6851 - val_accuracy: 0.6720 - val_loss: 0.6730\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5634 - loss: 0.6825 - val_accuracy: 0.6120 - val_loss: 0.6838\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5666 - loss: 0.6846 - val_accuracy: 0.5480 - val_loss: 0.7044\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5842 - loss: 0.6777 - val_accuracy: 0.6640 - val_loss: 0.6786\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5658 - loss: 0.6832 - val_accuracy: 0.5520 - val_loss: 0.7096\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 997ms/step - accuracy: 0.5768 - loss: 0.6771 - val_accuracy: 0.5600 - val_loss: 0.7084\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5160 - loss: 0.6913 - val_accuracy: 0.4600 - val_loss: 0.7412\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5319 - loss: 0.6905 - val_accuracy: 0.6440 - val_loss: 0.6822\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5460 - loss: 0.6805 - val_accuracy: 0.3840 - val_loss: 0.7575\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5804 - loss: 0.6798 - val_accuracy: 0.6720 - val_loss: 0.6734\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5378 - loss: 0.6828 - val_accuracy: 0.5760 - val_loss: 0.7155\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5750 - loss: 0.6827 - val_accuracy: 0.6320 - val_loss: 0.6837\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5704 - loss: 0.6780 - val_accuracy: 0.5440 - val_loss: 0.7185\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 990ms/step - accuracy: 0.5601 - loss: 0.6828 - val_accuracy: 0.5800 - val_loss: 0.7152\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5757 - loss: 0.6704 - val_accuracy: 0.5200 - val_loss: 0.7547\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 999ms/step - accuracy: 0.5744 - loss: 0.6794 - val_accuracy: 0.4560 - val_loss: 0.7522\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5729 - loss: 0.6727 - val_accuracy: 0.4760 - val_loss: 0.7671\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 998ms/step - accuracy: 0.5531 - loss: 0.6830 - val_accuracy: 0.5720 - val_loss: 0.7399\n",
            "Epoch 58/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5921 - loss: 0.6760 - val_accuracy: 0.5920 - val_loss: 0.7082\n",
            "Epoch 59/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 996ms/step - accuracy: 0.5927 - loss: 0.6744 - val_accuracy: 0.5160 - val_loss: 0.7544\n",
            "Epoch 60/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5585 - loss: 0.6765 - val_accuracy: 0.5880 - val_loss: 0.7294\n",
            "Epoch 61/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5585 - loss: 0.6684 - val_accuracy: 0.7240 - val_loss: 0.6749\n",
            "Epoch 62/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5756 - loss: 0.6731 - val_accuracy: 0.6120 - val_loss: 0.7237\n",
            "Epoch 63/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5894 - loss: 0.6656 - val_accuracy: 0.6120 - val_loss: 0.7117\n",
            "Epoch 64/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 988ms/step - accuracy: 0.5679 - loss: 0.6674 - val_accuracy: 0.6920 - val_loss: 0.6851\n",
            "Epoch 65/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5477 - loss: 0.6884 - val_accuracy: 0.6320 - val_loss: 0.7072\n",
            "Epoch 66/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 998ms/step - accuracy: 0.5865 - loss: 0.6591 - val_accuracy: 0.6760 - val_loss: 0.6919\n",
            "Epoch 67/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5973 - loss: 0.6598 - val_accuracy: 0.6520 - val_loss: 0.7163\n",
            "Epoch 68/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5788 - loss: 0.6690 - val_accuracy: 0.6480 - val_loss: 0.7014\n",
            "Epoch 69/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6144 - loss: 0.6593 - val_accuracy: 0.5800 - val_loss: 0.7354\n",
            "Epoch 70/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5779 - loss: 0.6652 - val_accuracy: 0.6320 - val_loss: 0.7029\n",
            "Epoch 71/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 999ms/step - accuracy: 0.5607 - loss: 0.6766 - val_accuracy: 0.5560 - val_loss: 0.7344\n",
            "Epoch 72/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5828 - loss: 0.6726 - val_accuracy: 0.5520 - val_loss: 0.7449\n",
            "Epoch 73/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5878 - loss: 0.6659 - val_accuracy: 0.6080 - val_loss: 0.7066\n",
            "Epoch 74/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5763 - loss: 0.6680 - val_accuracy: 0.4200 - val_loss: 0.8386\n",
            "Epoch 75/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5872 - loss: 0.6542 - val_accuracy: 0.5560 - val_loss: 0.7484\n",
            "Epoch 76/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5822 - loss: 0.6595 - val_accuracy: 0.6520 - val_loss: 0.7093\n",
            "Epoch 77/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5869 - loss: 0.6636 - val_accuracy: 0.4560 - val_loss: 0.7823\n",
            "Epoch 78/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5904 - loss: 0.6621 - val_accuracy: 0.6000 - val_loss: 0.7257\n",
            "Epoch 79/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.6156 - loss: 0.6578 - val_accuracy: 0.4960 - val_loss: 0.7761\n",
            "Epoch 80/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5891 - loss: 0.6728 - val_accuracy: 0.5440 - val_loss: 0.7887\n",
            "Epoch 81/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5744 - loss: 0.6622 - val_accuracy: 0.5280 - val_loss: 0.7800\n",
            "Epoch 82/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5820 - loss: 0.6682 - val_accuracy: 0.5480 - val_loss: 0.7816\n",
            "Epoch 83/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5910 - loss: 0.6603 - val_accuracy: 0.6960 - val_loss: 0.7011\n",
            "Epoch 84/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6000 - loss: 0.6498 - val_accuracy: 0.6200 - val_loss: 0.7286\n",
            "Epoch 85/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5669 - loss: 0.6644 - val_accuracy: 0.5880 - val_loss: 0.7239\n",
            "Epoch 86/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5896 - loss: 0.6598 - val_accuracy: 0.6920 - val_loss: 0.6775\n",
            "Epoch 87/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5971 - loss: 0.6665 - val_accuracy: 0.5760 - val_loss: 0.7213\n",
            "Epoch 88/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5782 - loss: 0.6662 - val_accuracy: 0.6120 - val_loss: 0.7021\n",
            "Epoch 89/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5793 - loss: 0.6718 - val_accuracy: 0.5160 - val_loss: 0.7686\n",
            "Epoch 90/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5886 - loss: 0.6664 - val_accuracy: 0.6040 - val_loss: 0.7441\n",
            "Epoch 91/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6056 - loss: 0.6494 - val_accuracy: 0.5640 - val_loss: 0.7653\n",
            "Epoch 92/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.6000 - loss: 0.6560 - val_accuracy: 0.5240 - val_loss: 0.7808\n",
            "Epoch 93/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5940 - loss: 0.6635 - val_accuracy: 0.6080 - val_loss: 0.7604\n",
            "Epoch 94/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5798 - loss: 0.6557 - val_accuracy: 0.6240 - val_loss: 0.7426\n",
            "Epoch 95/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5966 - loss: 0.6433 - val_accuracy: 0.6320 - val_loss: 0.7426\n",
            "Epoch 96/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.6215 - loss: 0.6454 - val_accuracy: 0.6320 - val_loss: 0.7275\n",
            "Epoch 97/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6157 - loss: 0.6513 - val_accuracy: 0.6400 - val_loss: 0.7328\n",
            "Epoch 98/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5761 - loss: 0.6581 - val_accuracy: 0.7120 - val_loss: 0.6861\n",
            "Epoch 99/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6149 - loss: 0.6534 - val_accuracy: 0.6720 - val_loss: 0.6941\n",
            "Epoch 100/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.6132 - loss: 0.6448 - val_accuracy: 0.5840 - val_loss: 0.7653\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 547ms/step - accuracy: 0.5956 - loss: 0.7330\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 528ms/step\n",
            "Threshold 0.10 → F1 Score: 0.9429\n",
            "Threshold 0.20 → F1 Score: 0.9336\n",
            "Threshold 0.30 → F1 Score: 0.9174\n",
            "Threshold 0.40 → F1 Score: 0.8598\n",
            "Threshold 0.50 → F1 Score: 0.7263\n",
            "Threshold 0.60 → F1 Score: 0.3105\n",
            "Threshold 0.70 → F1 Score: 0.1377\n",
            "Threshold 0.80 → F1 Score: 0.0342\n",
            "Threshold 0.90 → F1 Score: 0.0000\n",
            "\n",
            "Best Threshold: 0.10 → F1 Score: 0.9429\n",
            "Test Accuracy (train size=1000): 58.40%\n",
            "AUC: 0.5168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_GEp7AlP2Gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNDC0WrwkWpEQPrsfxMzcXi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}