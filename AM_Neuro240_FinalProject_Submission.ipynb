{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdiVM/Neuro240/blob/main/AM_Neuro240_FinalProject_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code for my final assignment. Note that for ease and readability, all my previous code is available with its respective checkpoints here: https://github.com/AdiVM/Neuro240\n",
        "\n",
        "Much of my code was written for these checkpoints, and rather than submit it all again as one ipynb, I have just uploaded the respective code to github."
      ],
      "metadata": {
        "id": "kHCn6PnUOk3g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_PdcJlQyDlD",
        "outputId": "b1c28f13-661c-4400-8f59-df77e29cdb7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# All future runs can start here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8-T_YFvyEpR",
        "outputId": "c9027ee4-52a0-4145-aa25-0d55a7014e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metdata loaded\n",
            "Total matching images found: 50000\n"
          ]
        }
      ],
      "source": [
        "metadata_path = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/Data_Entry_2017_v2020.csv\"\n",
        "image_folder = \"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/images\"\n",
        "\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(\"Metdata loaded\")\n",
        "\n",
        "# Filtering the metadata to find images labeled either no finding or those containing the word mass\n",
        "filtered_metadata = metadata[\n",
        "    (metadata[\"Finding Labels\"] == \"No Finding\") |\n",
        "    (metadata[\"Finding Labels\"].str.contains(\"Mass\", na=False))\n",
        "]\n",
        "\n",
        "filtered_image_indexes = set(filtered_metadata[\"Image Index\"])\n",
        "filtered_metadata = filtered_metadata.head(50000)\n",
        "\n",
        "matching_images = sorted(list(filtered_metadata[\"Image Index\"]))\n",
        "\n",
        "# Convert to stored list\n",
        "matching_images = sorted(list(matching_images))\n",
        "\n",
        "print(f\"Total matching images found: {len(matching_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xKqoPmUyLE-",
        "outputId": "bfe8a279-86a2-4786-9c54-4481a443dfa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding Labels\n",
            "No Finding                                                            45542\n",
            "Mass                                                                   1708\n",
            "Infiltration|Mass                                                       329\n",
            "Mass|Nodule                                                             293\n",
            "Effusion|Mass                                                           285\n",
            "                                                                      ...  \n",
            "Atelectasis|Cardiomegaly|Consolidation|Effusion|Mass|Nodule               1\n",
            "Atelectasis|Consolidation|Effusion|Mass|Nodule|Pleural_Thickening         1\n",
            "Cardiomegaly|Consolidation|Effusion|Mass|Nodule|Pleural_Thickening        1\n",
            "Cardiomegaly|Consolidation|Effusion|Infiltration|Mass|Nodule              1\n",
            "Edema|Fibrosis|Infiltration|Mass                                          1\n",
            "Name: count, Length: 258, dtype: int64\n",
            "Finding Labels\n",
            "No Finding    45542\n",
            "Mass           4458\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Now to perform stratified shuffle split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        " # Check class distribution before splitting\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n",
        "\n",
        "# There are many small classes of mass, so need to group them all together before splitting\n",
        "# Standardize labels: Convert anything containing \"Mass\" to just \"Mass\"\n",
        "filtered_metadata[\"Finding Labels\"] = filtered_metadata[\"Finding Labels\"].apply(\n",
        "    lambda x: \"Mass\" if \"Mass\" in x else x\n",
        ")\n",
        "\n",
        "# Verify new label counts\n",
        "print(filtered_metadata[\"Finding Labels\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zxHdem9r6Ewk"
      },
      "outputs": [],
      "source": [
        "label_map = {\"No Finding\": 0, \"Mass\": 1}\n",
        "filtered_metadata[\"Label\"] = filtered_metadata[\"Finding Labels\"].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xripsguQyPqP",
        "outputId": "585d2e9c-25c1-4dfa-982a-a3f13f6f9a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Label\n",
            "0    36434\n",
            "1     3566\n",
            "Name: count, dtype: int64\n",
            "Testing Set:\n",
            "Label\n",
            "0    9108\n",
            "1     892\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Split the data while ensuring proportional distribution of classes\n",
        "train_metadata, test_metadata = train_test_split(\n",
        "    filtered_metadata,\n",
        "    test_size=0.2,\n",
        "    stratify=filtered_metadata[\"Label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Class distribution in train and test sets\n",
        "print(\"Training set:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"Testing Set:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6h6-YhWySET",
        "outputId": "fc010f02-b4ee-4ef3-d688-efc0c3209adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train metadata entries: 40000\n",
            "Test metadata entries: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train metadata entries: {len(train_metadata)}\")\n",
        "print(f\"Test metadata entries: {len(test_metadata)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-cLJqxySmw",
        "outputId": "00c96bec-e76d-43c7-b73c-e2a7653dc364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images found: 40000\n",
            "Total test images found: 10000\n",
            "Sample train images: ['00000002_000.png', '00000004_000.png', '00000005_000.png', '00000005_002.png', '00000005_003.png', '00000005_004.png', '00000005_005.png', '00000006_000.png', '00000007_000.png', '00000011_002.png']\n",
            "Sample test images: ['00000005_001.png', '00000008_001.png', '00000011_001.png', '00000011_003.png', '00000013_000.png', '00000013_017.png', '00000013_029.png', '00000013_030.png', '00000018_000.png', '00000032_049.png']\n"
          ]
        }
      ],
      "source": [
        "# Filtering metdata\n",
        "# Convert \"Image Index\" column to a set for fast lookup\n",
        "train_image_files = set(train_metadata[\"Image Index\"])\n",
        "test_image_files = set(test_metadata[\"Image Index\"])\n",
        "\n",
        "train_images = sorted(list(train_image_files))\n",
        "test_images = sorted(list(test_image_files))\n",
        "\n",
        "# Convert to sorted lists for consistency\n",
        "train_images = sorted(list(train_images))\n",
        "test_images = sorted(list(test_images))\n",
        "\n",
        "\n",
        "print(f\"Total train images found: {len(train_images)}\")\n",
        "print(f\"Total test images found: {len(test_images)}\")\n",
        "\n",
        "# Print a few samples\n",
        "print(\"Sample train images:\", train_images[:10])\n",
        "print(\"Sample test images:\", test_images[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JSullbIDyWwk"
      },
      "outputs": [],
      "source": [
        "# I will use TensorFlow for model training\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaTNWs9lyY6O",
        "outputId": "b6f97686-bfb7-4419-b7b1-9e395b5d3bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39997 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3 invalid image filename(s) in x_col=\"Image Index\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "# Image preprocessing parameters\n",
        "image_size = (224, 224)  # Resize images\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Normalize pixel values\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Only rescale for testing\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load train images from directory\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")\n",
        "\n",
        "# Load test images\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_metadata,\n",
        "    directory=image_folder,\n",
        "    x_col=\"Image Index\",\n",
        "    y_col=\"Label\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lApFIyKt6dYr",
        "outputId": "a79d85ba-a8c9-447b-803e-08e2f8d33168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train distribution:\n",
            "Label\n",
            "0    36434\n",
            "1     3566\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test distribution:\n",
            "Label\n",
            "0    9108\n",
            "1     892\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Train distribution:\")\n",
        "print(train_metadata[\"Label\"].value_counts())\n",
        "\n",
        "print(\"\\nTest distribution:\")\n",
        "print(test_metadata[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What follows is a key contributution since the Almost There checkpoint."
      ],
      "metadata": {
        "id": "Pavnn1goPdjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "We89N-5FJo92"
      },
      "outputs": [],
      "source": [
        "# This is my key function. I use 30 epochs for much better performance, a perfectly balanced class distribtuion within the training set (50& control, 50% mass -- not the classweighting\n",
        "# equation I previously used) implement early stopping for efficiency, and evaluate savling loss and accuracy curves.\n",
        "\n",
        "def train_model_with_class_weighting(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=30,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/final_results\"):\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from tensorflow.keras.callbacks import EarlyStopping\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Sample balanced subset\n",
        "    half_size = train_size // 2\n",
        "    mass_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"Mass\"].sample(half_size, random_state=42)\n",
        "    no_finding_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"No Finding\"].sample(half_size, random_state=42)\n",
        "    train_metadata_subset = pd.concat([mass_subset, no_finding_subset]).sample(frac=1, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    # Save class distribution\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    save_distribution(train_metadata_subset, \"train\")\n",
        "    save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Class weights\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"]\n",
        "    classes = np.unique(y_train_labels)\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_labels)\n",
        "    class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "    # Old Sequential Model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save loss & accuracy curves\n",
        "    pd.DataFrame(history.history).to_csv(f\"{result_prefix}_training_history.csv\", index=False)\n",
        "    for metric in ['loss', 'accuracy']:\n",
        "        plt.figure()\n",
        "        plt.plot(history.history[metric], label='Train')\n",
        "        plt.plot(history.history[f'val_{metric}'], label='Validation')\n",
        "        plt.title(f'{metric.capitalize()} over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f\"{result_prefix}_{metric}_curve.png\")\n",
        "        plt.close()\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    thresholds = np.linspace(0.1, 0.9, 9)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_preds = None\n",
        "\n",
        "    for t in thresholds:\n",
        "        preds = (y_pred_proba > t).astype(int)\n",
        "        f1 = f1_score(y_true, preds)\n",
        "        print(f\"Threshold {t:.2f} → F1 Score: {f1:.4f}\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = t\n",
        "            best_preds = preds\n",
        "\n",
        "    print(f\"\\nBest Threshold: {best_threshold:.2f} → F1 Score: {best_f1:.4f}\")\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, best_preds)\n",
        "\n",
        "    confusion_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Mass\", \"No Finding\"],\n",
        "        columns=[\"Predicted Mass\", \"Predicted No Finding\"]\n",
        "    )\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": test_generator.filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": best_preds,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    with open(f\"{result_prefix}_best_threshold.txt\", \"w\") as f:\n",
        "        f.write(f\"Best threshold: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc, result_prefix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking results without early stopping\n",
        "def train_model_with_class_weighting_nostop(train_metadata, test_metadata, image_folder,\n",
        "                            train_size,\n",
        "                            image_size=(224, 224), batch_size=32, epochs=30,\n",
        "                            output_dir=\"/content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/final_results/nostop\"):\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    from tensorflow.keras import Input, Model\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    result_prefix = os.path.join(output_dir, f\"train_{train_size}\")\n",
        "\n",
        "    # Sample balanced subset\n",
        "    half_size = train_size // 2\n",
        "    mass_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"Mass\"].sample(half_size, random_state=42)\n",
        "    no_finding_subset = train_metadata[train_metadata[\"Finding Labels\"] == \"No Finding\"].sample(half_size, random_state=42)\n",
        "    train_metadata_subset = pd.concat([mass_subset, no_finding_subset]).sample(frac=1, random_state=42)\n",
        "    test_metadata_subset = test_metadata.sample(int(train_size / 4), random_state=42)\n",
        "\n",
        "    # Save class distribution\n",
        "    def save_distribution(df, name):\n",
        "        counts = df[\"Finding Labels\"].value_counts()\n",
        "        percents = counts / counts.sum() * 100\n",
        "        dist_df = pd.DataFrame({\"Count\": counts, \"Percent\": percents})\n",
        "        dist_df.to_csv(f\"{result_prefix}_{name}_distribution.csv\")\n",
        "        return dist_df\n",
        "\n",
        "    save_distribution(train_metadata_subset, \"train\")\n",
        "    save_distribution(test_metadata_subset, \"test\")\n",
        "\n",
        "    # Data generators\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False\n",
        "    )\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_metadata_subset,\n",
        "        directory=image_folder,\n",
        "        x_col=\"Image Index\",\n",
        "        y_col=\"Finding Labels\",\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"binary\",\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Class weights\n",
        "    y_train_labels = train_metadata_subset[\"Finding Labels\"]\n",
        "    classes = np.unique(y_train_labels)\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_labels)\n",
        "    class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "    # Model\n",
        "    # # Old Sequential Model\n",
        "    # model = Sequential([\n",
        "    #     Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "    #     MaxPooling2D(pool_size=(2, 2)),\n",
        "    #     Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    #     MaxPooling2D(pool_size=(2, 2)),\n",
        "    #     Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    #     MaxPooling2D(pool_size=(2, 2)),\n",
        "    #     Flatten(),\n",
        "    #     Dense(128, activation=\"relu\"),\n",
        "    #     Dropout(0.5),\n",
        "    #     Dense(1, activation=\"sigmoid\")\n",
        "    # ])\n",
        "\n",
        "    # Functional API model — that should work with Grad-CAM\n",
        "\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    x = Conv2D(32, (3, 3), activation=\"relu\")(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    # Rest of code continues as normal\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=test_generator,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save loss & accuracy curves\n",
        "    pd.DataFrame(history.history).to_csv(f\"{result_prefix}_training_history.csv\", index=False)\n",
        "    for metric in ['loss', 'accuracy']:\n",
        "        plt.figure()\n",
        "        plt.plot(history.history[metric], label='Train')\n",
        "        plt.plot(history.history[f'val_{metric}'], label='Validation')\n",
        "        plt.title(f'{metric.capitalize()} over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f\"{result_prefix}_{metric}_curve.png\")\n",
        "        plt.close()\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(test_generator)\n",
        "    y_pred_proba = model.predict(test_generator).flatten()\n",
        "    y_true = test_generator.classes\n",
        "\n",
        "    thresholds = np.linspace(0.1, 0.9, 9)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    best_preds = None\n",
        "\n",
        "    for t in thresholds:\n",
        "        preds = (y_pred_proba > t).astype(int)\n",
        "        f1 = f1_score(y_true, preds)\n",
        "        print(f\"Threshold {t:.2f} → F1 Score: {f1:.4f}\")\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = t\n",
        "            best_preds = preds\n",
        "\n",
        "    print(f\"\\nBest Threshold: {best_threshold:.2f} → F1 Score: {best_f1:.4f}\")\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    cm = confusion_matrix(y_true, best_preds)\n",
        "\n",
        "    confusion_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Mass\", \"No Finding\"],\n",
        "        columns=[\"Predicted Mass\", \"Predicted No Finding\"]\n",
        "    )\n",
        "    confusion_df.to_csv(f\"{result_prefix}_confusion_matrix.csv\")\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        \"Filename\": test_generator.filenames,\n",
        "        \"TrueLabel\": y_true,\n",
        "        \"PredictedLabel\": best_preds,\n",
        "        \"PredictedProb\": y_pred_proba\n",
        "    })\n",
        "    results_df.to_csv(f\"{result_prefix}_predictions.csv\", index=False)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{result_prefix}_roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    with open(f\"{result_prefix}_best_threshold.txt\", \"w\") as f:\n",
        "        f.write(f\"Best threshold: {best_threshold:.2f}, F1: {best_f1:.4f}\")\n",
        "\n",
        "    print(f\"Test Accuracy (train size={train_size}): {test_acc * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return model, history, test_acc, auc, result_prefix"
      ],
      "metadata": {
        "id": "ZQrwWIjqXohC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c9HfxrncMS0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a66571-ddb5-4587-e4f6-d057e99c4ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 validated image filenames belonging to 2 classes.\n",
            "Found 250 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 21s/step - accuracy: 0.5071 - loss: 1.2881 - val_accuracy: 0.8080 - val_loss: 0.6888\n",
            "Epoch 2/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5164 - loss: 0.6931 - val_accuracy: 0.7560 - val_loss: 0.6913\n",
            "Epoch 3/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5113 - loss: 0.6929 - val_accuracy: 0.7640 - val_loss: 0.6889\n",
            "Epoch 4/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.5114 - loss: 0.6920 - val_accuracy: 0.6920 - val_loss: 0.6919\n",
            "Epoch 5/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.4750 - loss: 0.6922 - val_accuracy: 0.3520 - val_loss: 0.6929\n",
            "Epoch 6/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5091 - loss: 0.6932 - val_accuracy: 0.8120 - val_loss: 0.6832\n",
            "Epoch 7/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5080 - loss: 0.6923 - val_accuracy: 0.6760 - val_loss: 0.6855\n",
            "Epoch 8/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5462 - loss: 0.6920 - val_accuracy: 0.6960 - val_loss: 0.6847\n",
            "Epoch 9/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5284 - loss: 0.6947 - val_accuracy: 0.5600 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5507 - loss: 0.6950 - val_accuracy: 0.3200 - val_loss: 0.7000\n",
            "Epoch 11/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5549 - loss: 0.6958 - val_accuracy: 0.3360 - val_loss: 0.6972\n",
            "Epoch 12/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5393 - loss: 0.6911 - val_accuracy: 0.2560 - val_loss: 0.7127\n",
            "Epoch 13/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5262 - loss: 0.6909 - val_accuracy: 0.5760 - val_loss: 0.7045\n",
            "Epoch 14/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.5166 - loss: 0.6908 - val_accuracy: 0.6440 - val_loss: 0.6951\n",
            "Epoch 15/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.5344 - loss: 0.6883 - val_accuracy: 0.3400 - val_loss: 0.7221\n",
            "Epoch 16/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5413 - loss: 0.6901 - val_accuracy: 0.4640 - val_loss: 0.7016\n",
            "Epoch 17/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5302 - loss: 0.6875 - val_accuracy: 0.4080 - val_loss: 0.7259\n",
            "Epoch 18/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5305 - loss: 0.6910 - val_accuracy: 0.4760 - val_loss: 0.7152\n",
            "Epoch 19/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5246 - loss: 0.6904 - val_accuracy: 0.6160 - val_loss: 0.7019\n",
            "Epoch 20/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5333 - loss: 0.6912 - val_accuracy: 0.5640 - val_loss: 0.6992\n",
            "Epoch 21/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5557 - loss: 0.6886 - val_accuracy: 0.4680 - val_loss: 0.7191\n",
            "Epoch 22/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5374 - loss: 0.6890 - val_accuracy: 0.5160 - val_loss: 0.7114\n",
            "Epoch 23/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5707 - loss: 0.6833 - val_accuracy: 0.5440 - val_loss: 0.7251\n",
            "Epoch 24/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5126 - loss: 0.6928 - val_accuracy: 0.6520 - val_loss: 0.6924\n",
            "Epoch 25/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5315 - loss: 0.6897 - val_accuracy: 0.4560 - val_loss: 0.7093\n",
            "Epoch 26/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5388 - loss: 0.6858 - val_accuracy: 0.4480 - val_loss: 0.7293\n",
            "Epoch 27/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5262 - loss: 0.6843 - val_accuracy: 0.5720 - val_loss: 0.7040\n",
            "Epoch 28/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5762 - loss: 0.6859 - val_accuracy: 0.5680 - val_loss: 0.7087\n",
            "Epoch 29/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.5637 - loss: 0.6825 - val_accuracy: 0.5160 - val_loss: 0.7376\n",
            "Epoch 30/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5491 - loss: 0.6813 - val_accuracy: 0.5440 - val_loss: 0.7474\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 671ms/step - accuracy: 0.5367 - loss: 0.7551\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 522ms/step\n",
            "Threshold 0.10 → F1 Score: 0.9583\n",
            "Threshold 0.20 → F1 Score: 0.9583\n",
            "Threshold 0.30 → F1 Score: 0.9362\n",
            "Threshold 0.40 → F1 Score: 0.8753\n",
            "Threshold 0.50 → F1 Score: 0.6902\n",
            "Threshold 0.60 → F1 Score: 0.0508\n",
            "Threshold 0.70 → F1 Score: 0.0342\n",
            "Threshold 0.80 → F1 Score: 0.0342\n",
            "Threshold 0.90 → F1 Score: 0.0172\n",
            "\n",
            "Best Threshold: 0.10 → F1 Score: 0.9583\n",
            "Test Accuracy (train size=1000): 54.40%\n",
            "AUC: 0.4801\n"
          ]
        }
      ],
      "source": [
        "model_1000_class, history_1000_class, acc_1000_class, auc_1000_class, result_prefix_1000 = train_model_with_class_weighting_nostop(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM Visualization Block (fixed)\n",
        "def generate_gradcam_visualizations(model, test_generator, results_df, result_prefix,\n",
        "                                    image_folder, num_examples=5):\n",
        "    import tensorflow as tf\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    from tensorflow.keras.preprocessing import image as keras_image\n",
        "    import numpy as np\n",
        "\n",
        "    os.makedirs(f\"{result_prefix}_gradcam\", exist_ok=True)\n",
        "\n",
        "    # Force-build model by passing dummy input (fix for Sequential)\n",
        "    dummy_input = tf.zeros((1, 224, 224, 3))\n",
        "    _ = model(dummy_input)\n",
        "\n",
        "    # Get last convolutional layer name\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            last_conv_layer_name = layer.name\n",
        "            break\n",
        "    else:\n",
        "        raise ValueError(\"No Conv2D layer found in model.\")\n",
        "\n",
        "    # Build Grad-CAM model\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=[model.input],\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Helper to load and preprocess image\n",
        "    def load_image(img_path, target_size):\n",
        "        img = keras_image.load_img(img_path, target_size=target_size)\n",
        "        array = keras_image.img_to_array(img) / 255.0\n",
        "        return np.expand_dims(array, axis=0), img\n",
        "\n",
        "    # Get indices of false positives and false negatives\n",
        "    fp_idx = results_df[(results_df[\"TrueLabel\"] == 0) & (results_df[\"PredictedLabel\"] == 1)].index\n",
        "    fn_idx = results_df[(results_df[\"TrueLabel\"] == 1) & (results_df[\"PredictedLabel\"] == 0)].index\n",
        "\n",
        "    selected_idx = list(fp_idx[:num_examples]) + list(fn_idx[:num_examples])\n",
        "    selected_type = ['FP'] * min(num_examples, len(fp_idx)) + ['FN'] * min(num_examples, len(fn_idx))\n",
        "\n",
        "    for i, idx in enumerate(selected_idx):\n",
        "        filename = results_df.loc[idx, \"Filename\"]\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img_array, original_img = load_image(img_path, target_size=(224, 224))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            conv_output, predictions = grad_model(img_array)\n",
        "            loss = predictions[:, 0]\n",
        "\n",
        "        grads = tape.gradient(loss, conv_output)\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "        conv_output = conv_output[0]\n",
        "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "\n",
        "        # Normalize and resize\n",
        "        heatmap = np.maximum(heatmap, 0)\n",
        "        heatmap /= np.max(heatmap) + 1e-8\n",
        "        heatmap = cv2.resize(heatmap, (224, 224))\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        superimposed_img = cv2.addWeighted(np.array(original_img).astype(np.uint8), 0.6, heatmap, 0.4, 0)\n",
        "        output_path = os.path.join(result_prefix + \"_gradcam\", f\"{selected_type[i]}_{filename}\")\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    print(f\"Grad-CAM saved for {len(selected_idx)} samples in: {result_prefix}_gradcam\")"
      ],
      "metadata": {
        "id": "eq8pPRGSQJE0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Force-build model explicitly for Grad-CAM (do this BEFORE calling generate_gradcam_visualizations)\n",
        "import tensorflow as tf\n",
        "\n",
        "# Build model by passing a real-shape dummy image\n",
        "model_1000_class(tf.zeros((1, 224, 224, 3)))  # THIS is what initializes model.input/output\n",
        "\n",
        "import numpy as np\n",
        "# Now call Grad-CAM\n",
        "results_df = pd.read_csv(f\"{result_prefix_1000}_predictions.csv\")\n",
        "generate_gradcam_visualizations(model_1000_class, test_generator, results_df, result_prefix_1000, image_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBDbGuGIRC7i",
        "outputId": "148c5b04-2236-4943-bdb5-a06946e2bc5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grad-CAM saved for 5 samples in: /content/drive/MyDrive/NIH_ChestXRay_Data_Neuro240/final_results/nostop/train_1000_gradcam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTcjxQE1Wuux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000_class, history_1000_class, acc_1000_class, auc_1000_class, result_prefix_1000 = train_model_with_class_weighting_nostop(\n",
        "    train_metadata=train_metadata,\n",
        "    test_metadata=test_metadata,\n",
        "    image_folder=image_folder,\n",
        "    train_size=1000\n",
        ")"
      ],
      "metadata": {
        "id": "DNpaGKuvW8qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_GEp7AlP2Gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMOtAWDE9u4QF0IuGMpT6jJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}